{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PracticalExam_DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDlkIfca5yCx",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Practical Exam (Test 1)\n",
        "\n",
        "#Jenil Gathani (J061) \n",
        "\n",
        "#B.tech Data Science 3rd Year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICY2fMvCwAdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHBuLA1SwAhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6txUmLbwAj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cReAREBNwAmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ8SKc4twAq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M1deBZIwAov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f714e4d-dbde-40c2-a9a5-932e0eedbac5"
      },
      "source": [
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjRpx7J-wAtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YCk_p2pwAvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6imNhoZwAx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "a5a8a24e-1ec2-4328-a74f-3e6153d8b41d"
      },
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2284 - acc: 0.9298 - val_loss: 0.1035 - val_acc: 0.9675\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0834 - acc: 0.9741 - val_loss: 0.0903 - val_acc: 0.9703\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0557 - acc: 0.9831 - val_loss: 0.0922 - val_acc: 0.9739\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0396 - acc: 0.9879 - val_loss: 0.0717 - val_acc: 0.9810\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0734 - val_acc: 0.9805\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0799 - val_acc: 0.9818\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0176 - acc: 0.9948 - val_loss: 0.1081 - val_acc: 0.9763\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0153 - acc: 0.9953 - val_loss: 0.0883 - val_acc: 0.9815\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0923 - val_acc: 0.9810\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0940 - val_acc: 0.9815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb082167390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVoLWBVgxUbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "adcf252f-6ba7-4eb8-f8e4-61cf6f1df46a"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.09398262414779983\n",
            "Test accuracy: 0.9815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl7kNiE91I5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "sgd= keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDw4NpKQ0wqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "0be2abaa-cbae-4e2c-c6f3-35be889cfa4b"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0857 - val_acc: 0.9837\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0845 - val_acc: 0.9837\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0838 - val_acc: 0.9836\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0835 - val_acc: 0.9833\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0832 - val_acc: 0.9833\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0829 - val_acc: 0.9835\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0828 - val_acc: 0.9834\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0826 - val_acc: 0.9834\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0825 - val_acc: 0.9833\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0824 - val_acc: 0.9834\n",
            "Test loss: 0.08242800025556246\n",
            "Test accuracy: 0.9834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-zuQoNc0wn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqXGhX570wls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "a5f73f37-96e8-4dde-9b4b-f58cac43abf0"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.1006 - val_acc: 0.9830\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.1104 - val_acc: 0.9821\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.1147 - val_acc: 0.9837\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.1314 - val_acc: 0.9801\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.1360 - val_acc: 0.9809\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.1303 - val_acc: 0.9834\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1256 - val_acc: 0.9836\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.1465 - val_acc: 0.9804\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.1416 - val_acc: 0.9809\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.1380 - val_acc: 0.9831\n",
            "Test loss: 0.1379930165573246\n",
            "Test accuracy: 0.9831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buNTGrFn0wjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxTM6Ogy0whD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "bf08333f-3cad-454c-8bed-56615388ecc0"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0266 - acc: 0.9960 - val_loss: 0.1229 - val_acc: 0.9834\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 8.9491e-04 - acc: 0.9999 - val_loss: 0.1192 - val_acc: 0.9834\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 6.8101e-04 - acc: 1.0000 - val_loss: 0.1145 - val_acc: 0.9840\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 5.6994e-04 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9843\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 5.6211e-04 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 0.9843\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 5.5900e-04 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9842\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 5.5681e-04 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9842\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 5.5512e-04 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9841\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 5.5376e-04 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9840\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 5.5264e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9841\n",
            "Test loss: 0.1153922005491035\n",
            "Test accuracy: 0.9841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks667dAp0wcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdpADV410wZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "7a4c53dd-4a8d-4889-ea23-ee1467339cd8"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 5.5154e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.4945e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9841\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 5.4793e-04 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9840\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 5.4678e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9840\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.4588e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9840\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 5.4519e-04 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9840\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 5.4462e-04 - acc: 1.0000 - val_loss: 0.1176 - val_acc: 0.9840\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 5.4413e-04 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 0.9840\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 5.4370e-04 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 0.9840\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 5.4334e-04 - acc: 1.0000 - val_loss: 0.1182 - val_acc: 0.9840\n",
            "Test loss: 0.11824952451131705\n",
            "Test accuracy: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TEVFR0s0wXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXmD4OMn2LuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "aef1a392-40b0-4a25-e5cc-42da922d9d00"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0201 - acc: 0.9953 - val_loss: 0.1314 - val_acc: 0.9791\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0133 - acc: 0.9962 - val_loss: 0.1247 - val_acc: 0.9812\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.1174 - val_acc: 0.9824\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0137 - acc: 0.9962 - val_loss: 0.1206 - val_acc: 0.9790\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.1230 - val_acc: 0.9792\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.1008 - val_acc: 0.9829\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0116 - acc: 0.9971 - val_loss: 0.1202 - val_acc: 0.9813\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0095 - acc: 0.9973 - val_loss: 0.1080 - val_acc: 0.9817\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.1231 - val_acc: 0.9798\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1238 - val_acc: 0.9805\n",
            "Test loss: 0.12383843698119067\n",
            "Test accuracy: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAl0bjzp2LrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyyC8OxN2Lo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "abf70fdb-efdd-4c64-a20f-c4de99b45a97"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=Epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1104 - val_acc: 0.9843\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 6.0581e-04 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9845\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 5.6234e-04 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9847\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5.5303e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9851\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5.4813e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9853\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 5.4469e-04 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9852\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 5.4237e-04 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9856\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 5.4069e-04 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9857\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 5.3957e-04 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9854\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 5.3878e-04 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9854\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 5.3826e-04 - acc: 1.0000 - val_loss: 0.1194 - val_acc: 0.9855\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 5.3795e-04 - acc: 1.0000 - val_loss: 0.1207 - val_acc: 0.9856\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 5.3774e-04 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9855\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5.3761e-04 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9857\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 5.3753e-04 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9858\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5.3748e-04 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9857\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 5.3744e-04 - acc: 1.0000 - val_loss: 0.1284 - val_acc: 0.9855\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 5.3742e-04 - acc: 1.0000 - val_loss: 0.1299 - val_acc: 0.9856\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5.3741e-04 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9853\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 5.3740e-04 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9857\n",
            "Test loss: 0.13192461220173765\n",
            "Test accuracy: 0.9857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9FAj8En2gWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "22be987b-4dcc-4023-8a93-0a6a39e1c76a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nceIwM7OS/H+23C8Nzlma7QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3yRP6-n2gQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "e4d52ea3-f046-43b2-bd0a-a6a3f35de47c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ww3nvK2gN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "f39c378b-a59f-4d5a-b21e-8f0d53b5bb22"
      },
      "source": [
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140396073727928 -->\n<g class=\"node\" id=\"node1\">\n<title>140396073727928</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_4_input: InputLayer</text>\n</g>\n<!-- 140396073728544 -->\n<g class=\"node\" id=\"node2\">\n<title>140396073728544</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_4: Dense</text>\n</g>\n<!-- 140396073727928&#45;&gt;140396073728544 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140396073727928-&gt;140396073728544</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140396073728208 -->\n<g class=\"node\" id=\"node3\">\n<title>140396073728208</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_5: Dense</text>\n</g>\n<!-- 140396073728544&#45;&gt;140396073728208 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140396073728544-&gt;140396073728208</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140396073782912 -->\n<g class=\"node\" id=\"node4\">\n<title>140396073782912</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_6: Dense</text>\n</g>\n<!-- 140396073728208&#45;&gt;140396073782912 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140396073728208-&gt;140396073782912</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gD2DdjDz_nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}